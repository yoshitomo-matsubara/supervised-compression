datasets:
  coco2017:
    name: &dataset_name 'coco2017'
    type: 'cocodetect'
    root: &root_dir !join ['~/dataset/', *dataset_name]
    splits:
      val:
        dataset_id: &coco_val !join [*dataset_name, '/val']
        images: !join [*root_dir, '/val2017']
        annotations: !join [*root_dir, '/annotations/instances_val2017.json']
        annotated_only: False
        is_segment: True
        transforms_params:
          - type: 'CustomRandomResize'
            params:
              min_size: 520
              max_size: 520
          - type: 'CustomToTensor'
            params:

models:
  model:
    name: 'InputCompressionSegmenter'
    params:
      post_transform_params:
        - type: 'Normalize'
          params:
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
      analysis_config:
        mean_std_file_size: True
      adaptive_pad_config:
        fill: 0
        padding_mode: 'constant'
        factor: 128
    compressor:
      name: 'FactorizedPriorAE'
      params:
        entropy_bottleneck_channels: 128
      ckpt: './resource/ckpt/input_compression/factorized_prior_ae_128ch-beta_0.00015625.pt'
    segmenter:
      name: 'deeplabv3_resnet50'
      params:
        pretrained: True
        progress: True
        pretrained_backbone: True
      ckpt: ''

test:
  test_data_loader:
    dataset_id: *coco_val
    random_sample: False
    batch_size: 1
    num_workers: 4
    collate_fn: 'coco_seg_eval_collate_fn'
